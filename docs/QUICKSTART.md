# ‚ö° Guia de In√≠cio R√°pido - Pipeline BRT

Este guia fornece instru√ß√µes passo a passo para colocar o pipeline em funcionamento o mais r√°pido poss√≠vel.

## ‚è±Ô∏è Tempo Estimado: 30 minutos

## üìã Checklist Pr√©-execu√ß√£o

- [ ] Python 3.8+ instalado
- [ ] Docker Desktop instalado e rodando
- [ ] Conta Google Cloud Platform criada
- [ ] Git instalado

## üöÄ Passos R√°pidos

### 1. Clone e Configure (5 min)

```powershell
# Clone o reposit√≥rio
git clone https://github.com/seu-usuario/desafio-civitas-brt.git
cd desafio-civitas-brt

# Crie ambiente virtual
python -m venv venv
.\venv\Scripts\Activate.ps1

# Instale depend√™ncias
pip install -r requirements.txt
```

### 2. Configure GCP (10 min)

#### 2.1. Crie Projeto GCP

1. Acesse: https://console.cloud.google.com/
2. Clique em "Novo Projeto"
3. Nome: `brt-pipeline-civitas`
4. Anote o Project ID

#### 2.2. Ative APIs

```powershell
# Via gcloud CLI (se instalado)
gcloud services enable bigquery.googleapis.com
gcloud services enable storage.googleapis.com

# OU via console:
# https://console.cloud.google.com/apis/library
```

#### 2.3. Crie Service Account

1. Acesse: https://console.cloud.google.com/iam-admin/serviceaccounts
2. "Criar Conta de Servi√ßo"
3. Nome: `brt-pipeline-sa`
4. Adicione roles:
   - BigQuery Admin
   - Storage Admin
5. Crie chave JSON
6. Baixe e salve em `config/gcp-credentials.json`

#### 2.4. Crie Recursos GCP

```powershell
# Bucket GCS
gcloud storage buckets create gs://brt-data-civitas --location=US

# Dataset BigQuery
bq mk --location=US brt_dataset
```

### 3. Configure Vari√°veis de Ambiente (2 min)

```powershell
# Copie o template
Copy-Item .env.example .env

# Edite .env e preencha:
# GCP_PROJECT_ID=seu-project-id
# GCS_BUCKET_NAME=brt-data-civitas
# GCP_CREDENTIALS_PATH=./config/gcp-credentials.json
```

### 4. Inicie Prefect Server (3 min)

```powershell
# Suba os containers
docker-compose up -d

# Aguarde 30 segundos
Start-Sleep -Seconds 30

# Verifique se est√° rodando
docker-compose ps
```

Acesse: http://localhost:4200

### 5. Instale Depend√™ncias DBT (2 min)

```powershell
cd dbt_brt
dbt deps
cd ..
```

### 6. Teste Individual de Componentes (5 min)

#### Teste 1: Captura da API

```powershell
python scripts/brt_api_capture.py
```

**Esperado:** 
```
‚úì Dados capturados: X registros
  vehicle_id | line | latitude | longitude | speed
```

#### Teste 2: Upload GCS (teste)

```powershell
python scripts/gcs_manager.py
```

**Esperado:**
```
‚úì Upload bem-sucedido: gs://brt-data-civitas/test/...
```

#### Teste 3: DBT Connection

```powershell
cd dbt_brt
dbt debug
```

**Esperado:**
```
‚úì Connection test: OK
```

### 7. Execute Pipeline Completo (3 min)

```powershell
# Execute o flow
python pipeline/brt_flow.py
```

**O que acontece:**
1. ‚úÖ Captura dados da API BRT
2. ‚úÖ Adiciona ao buffer (precisa rodar 10x para gerar CSV)
3. ‚úÖ Gera CSV (ap√≥s 10 capturas)
4. ‚úÖ Upload para GCS
5. ‚úÖ Cria tabela externa BigQuery
6. ‚úÖ Executa transforma√ß√µes Silver e Gold
7. ‚úÖ Executa testes de qualidade

## ‚úÖ Verifica√ß√£o de Sucesso

### Verifique no Prefect UI

Acesse: http://localhost:4200

- [ ] Flow aparece na lista
- [ ] √öltima execu√ß√£o foi sucesso
- [ ] Todas as tasks completaram

### Verifique no GCS

```powershell
gcloud storage ls gs://brt-data-civitas/brt-data/
```

- [ ] Arquivos CSV presentes

### Verifique no BigQuery

Acesse: https://console.cloud.google.com/bigquery

Execute:
```sql
-- Verifica tabela Bronze
SELECT COUNT(*) FROM `brt_dataset.brt_gps_raw` LIMIT 10;

-- Verifica view Silver
SELECT COUNT(*) FROM `brt_dataset_silver.stg_brt_gps_cleaned` LIMIT 10;

-- Verifica tabela Gold
SELECT * FROM `brt_dataset_gold.fct_brt_line_metrics` ORDER BY date_partition DESC LIMIT 10;
```

## üéØ Pr√≥ximos Passos

### Executar Pipeline Continuamente

```powershell
# Registre o flow no Prefect Server
python pipeline/brt_flow.py register

# O flow executar√° automaticamente a cada minuto
```

### Acessar Documenta√ß√£o DBT

```powershell
cd dbt_brt
dbt docs generate
dbt docs serve
```

Acesse: http://localhost:8080

### Criar Dashboard

Use BigQuery + Looker Studio:
1. Acesse: https://lookerstudio.google.com/
2. Crie nova fonte de dados ‚Üí BigQuery
3. Selecione: `brt_dataset_gold.fct_brt_line_metrics`
4. Crie visualiza√ß√µes:
   - Ve√≠culos ativos por linha
   - Velocidade m√©dia por per√≠odo
   - Mapa de calor de opera√ß√µes

## üêõ Problemas Comuns

### Erro: "Permission denied" no GCP

**Solu√ß√£o:**
```powershell
# Verifique se as credenciais est√£o corretas
$env:GOOGLE_APPLICATION_CREDENTIALS = ".\config\gcp-credentials.json"
```

### Erro: "Prefect Server n√£o conecta"

**Solu√ß√£o:**
```powershell
# Reinicie os containers
docker-compose restart

# Verifique logs
docker-compose logs prefect-server
```

### Erro: "API BRT timeout"

**Solu√ß√£o:**
- API pode estar temporariamente indispon√≠vel
- Aguarde alguns minutos e tente novamente
- Pipeline tem retry autom√°tico (3 tentativas)

### Erro: "DBT n√£o encontra tabela"

**Solu√ß√£o:**
```powershell
# Execute manualmente a cria√ß√£o da tabela externa
cd dbt_brt
dbt run-operation stage_external_sources
```

## üìä Dashboard de Monitoramento

Ap√≥s executar, voc√™ ter√°:

### Prefect UI (http://localhost:4200)
- Status do pipeline em tempo real
- Hist√≥rico de execu√ß√µes
- Logs detalhados

### DBT Docs (http://localhost:8080)
- Documenta√ß√£o de modelos
- Lineage de dados
- Schema das tabelas

### BigQuery Console
- Dados em tempo real
- Queries SQL
- An√°lises ad-hoc

## üí° Dicas

1. **Execute m√∫ltiplas vezes:**
   - Pipeline precisa rodar 10x para gerar primeiro CSV
   - Use loop para testar:
   ```powershell
   for ($i=1; $i -le 10; $i++) {
       python pipeline/brt_flow.py
       Start-Sleep -Seconds 60
   }
   ```

2. **Monitore custos GCP:**
   - Acesse: https://console.cloud.google.com/billing
   - Configure alertas de budget

3. **Backup de dados:**
   - CSVs s√£o salvos localmente em `data/`
   - GCS mant√©m hist√≥rico completo

## üéì Recursos Adicionais

- [Documenta√ß√£o Completa](../README.md)
- [Arquitetura Detalhada](./ARQUITETURA.md)
- [Prefect Docs](https://docs-v1.prefect.io/)
- [DBT Docs](https://docs.getdbt.com/)
- [BigQuery Docs](https://cloud.google.com/bigquery/docs)

---

**Pronto! Seu pipeline est√° funcionando! üéâ**

Se encontrar problemas, consulte a se√ß√£o de Troubleshooting no README principal ou abra uma issue no GitHub.
