# ğŸ—ï¸ Arquitetura do Pipeline BRT

## VisÃ£o Geral da Arquitetura Medallion

A arquitetura Medallion Ã© um padrÃ£o de design para organizar dados em camadas, cada uma com um nÃ­vel crescente de qualidade e agregaÃ§Ã£o.

## Camadas de Dados

### ğŸ¥‰ Camada Bronze (Raw Data)

**Objetivo:** Armazenar dados brutos exatamente como recebidos da fonte

**CaracterÃ­sticas:**
- âœ… Dados imutÃ¡veis
- âœ… HistÃ³rico completo
- âœ… Schema original preservado
- âœ… Formato: CSV no GCS
- âœ… ImplementaÃ§Ã£o: Tabela Externa BigQuery

**Fluxo:**
```
API BRT â†’ Captura Minuto a Minuto â†’ Buffer (10 min) â†’ CSV â†’ GCS â†’ BigQuery External Table
```

**Schema Bronze:**
```sql
CREATE EXTERNAL TABLE brt_dataset.brt_gps_raw (
    capture_timestamp TIMESTAMP,
    vehicle_id STRING,
    line STRING,
    latitude FLOAT64,
    longitude FLOAT64,
    speed FLOAT64,
    timestamp_gps TIMESTAMP,
    raw_data STRING
)
OPTIONS (
    format = 'CSV',
    uris = ['gs://brt-data-civitas/brt-data/*.csv'],
    skip_leading_rows = 1
);
```

### ğŸ¥ˆ Camada Silver (Cleaned Data)

**Objetivo:** Dados limpos, validados e enriquecidos

**TransformaÃ§Ãµes:**
1. **ValidaÃ§Ã£o de Qualidade**
   - Coordenadas GPS dentro dos limites do RJ
   - RemoÃ§Ã£o de valores nulos obrigatÃ³rios
   - ValidaÃ§Ã£o de tipos de dados

2. **Limpeza**
   - RemoÃ§Ã£o de duplicatas
   - NormalizaÃ§Ã£o de formatos
   - PadronizaÃ§Ã£o de strings

3. **Enriquecimento**
   - Campos derivados (data, hora, dia da semana)
   - CategorizaÃ§Ã£o (velocidade, perÃ­odo do dia)
   - Hash Ãºnico para rastreamento

**Fluxo:**
```
Bronze â†’ ValidaÃ§Ã£o â†’ DeduplicaÃ§Ã£o â†’ Enriquecimento â†’ Silver View
```

**Campos Adicionais:**
- `capture_date`: Data da captura
- `capture_hour`: Hora da captura
- `day_of_week`: Dia da semana (1-7)
- `is_valid_location`: Flag de validaÃ§Ã£o geogrÃ¡fica
- `speed_category`: CategorizaÃ§Ã£o da velocidade
- `period_of_day`: PerÃ­odo do dia
- `row_hash`: Hash Ãºnico MD5

### ğŸ¥‡ Camada Gold (Business Metrics)

**Objetivo:** Dados agregados e otimizados para consumo analÃ­tico

**CaracterÃ­sticas:**
- âœ… MÃ©tricas prÃ©-calculadas
- âœ… AgregaÃ§Ãµes de negÃ³cio
- âœ… Particionamento otimizado
- âœ… Cluster para performance
- âœ… Pronto para dashboards

**AgregaÃ§Ãµes:**
1. **DimensÃµes:**
   - Data (particionamento)
   - Linha BRT
   - PerÃ­odo do dia

2. **MÃ©tricas Operacionais:**
   - Total de veÃ­culos ativos
   - Total de observaÃ§Ãµes
   - Velocidade mÃ©dia/min/max
   - Desvio padrÃ£o de velocidade

3. **DistribuiÃ§Ãµes:**
   - VeÃ­culos parados
   - VeÃ­culos em velocidade lenta
   - VeÃ­culos em velocidade normal
   - VeÃ­culos em velocidade rÃ¡pida

4. **KPIs Calculados:**
   - % de veÃ­culos por categoria de velocidade
   - MÃ©dia de observaÃ§Ãµes por veÃ­culo
   - Centro geogrÃ¡fico de operaÃ§Ã£o

**OtimizaÃ§Ãµes:**
```sql
-- Particionamento por data
PARTITION BY date_partition

-- Cluster para queries frequentes
CLUSTER BY line, period_of_day
```

## Fluxo de Dados End-to-End

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    PIPELINE BRT - FLUXO COMPLETO                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  1ï¸âƒ£ CAPTURA (Prefect Task)                                     â”‚
â”‚     â”œâ”€ API BRT: jeap.rio.rj.gov.br/je-api/api/v2/gps          â”‚
â”‚     â”œâ”€ FrequÃªncia: A cada 1 minuto                             â”‚
â”‚     â”œâ”€ Retry: 3 tentativas com delay de 30s                    â”‚
â”‚     â””â”€ Output: DataFrame pandas                                â”‚
â”‚                                                                 â”‚
â”‚  2ï¸âƒ£ AGREGAÃ‡ÃƒO (Prefect Task)                                   â”‚
â”‚     â”œâ”€ Buffer em memÃ³ria: 10 capturas                          â”‚
â”‚     â”œâ”€ Trigger: Quando buffer completo                         â”‚
â”‚     â””â”€ Output: CSV local                                       â”‚
â”‚                                                                 â”‚
â”‚  3ï¸âƒ£ ARMAZENAMENTO (Prefect Task)                               â”‚
â”‚     â”œâ”€ Upload: CSV â†’ GCS                                       â”‚
â”‚     â”œâ”€ Bucket: gs://brt-data-civitas/brt-data/                â”‚
â”‚     â”œâ”€ Retry: 2 tentativas                                     â”‚
â”‚     â””â”€ Output: URI do arquivo                                  â”‚
â”‚                                                                 â”‚
â”‚  4ï¸âƒ£ BRONZE LAYER (DBT Operation)                               â”‚
â”‚     â”œâ”€ Comando: dbt run-operation stage_external_sources       â”‚
â”‚     â”œâ”€ AÃ§Ã£o: Cria/atualiza tabela externa                      â”‚
â”‚     â””â”€ Output: brt_dataset.brt_gps_raw                         â”‚
â”‚                                                                 â”‚
â”‚  5ï¸âƒ£ SILVER LAYER (DBT Run)                                     â”‚
â”‚     â”œâ”€ Comando: dbt run --models silver.*                      â”‚
â”‚     â”œâ”€ Modelo: stg_brt_gps_cleaned                             â”‚
â”‚     â”œâ”€ MaterializaÃ§Ã£o: View                                    â”‚
â”‚     â””â”€ Output: brt_dataset_silver.stg_brt_gps_cleaned          â”‚
â”‚                                                                 â”‚
â”‚  6ï¸âƒ£ GOLD LAYER (DBT Run)                                       â”‚
â”‚     â”œâ”€ Comando: dbt run --models gold.*                        â”‚
â”‚     â”œâ”€ Modelo: fct_brt_line_metrics                            â”‚
â”‚     â”œâ”€ MaterializaÃ§Ã£o: Table (particionada + cluster)          â”‚
â”‚     â””â”€ Output: brt_dataset_gold.fct_brt_line_metrics           â”‚
â”‚                                                                 â”‚
â”‚  7ï¸âƒ£ QUALIDADE (DBT Test)                                       â”‚
â”‚     â”œâ”€ Comando: dbt test                                       â”‚
â”‚     â”œâ”€ Testes: Schema + relacionamentos + valores              â”‚
â”‚     â””â”€ Output: RelatÃ³rio de qualidade                          â”‚
â”‚                                                                 â”‚
â”‚  8ï¸âƒ£ DOCUMENTAÃ‡ÃƒO (DBT Docs)                                    â”‚
â”‚     â”œâ”€ Comando: dbt docs generate                              â”‚
â”‚     â”œâ”€ AÃ§Ã£o: Gera site de documentaÃ§Ã£o                         â”‚
â”‚     â””â”€ Persiste: DescriÃ§Ãµes no BigQuery (+persist_docs)        â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Componentes TÃ©cnicos

### OrquestraÃ§Ã£o: Prefect v1.4.1

**Por que Prefect?**
- âœ… Interface web intuitiva
- âœ… Retry automÃ¡tico com backoff
- âœ… Monitoramento em tempo real
- âœ… Scheduling flexÃ­vel
- âœ… Logs centralizados

**Estrutura do Flow:**
```python
Flow("BRT Data Pipeline")
  â”œâ”€ Task: capture_brt_data()
  â”œâ”€ Task: add_to_buffer()
  â”œâ”€ Task: generate_csv()
  â”œâ”€ Task: upload_to_gcs()
  â”œâ”€ Task: run_dbt_external_table()
  â”œâ”€ Task: run_dbt_transformations()
  â””â”€ Task: run_dbt_tests()
```

### TransformaÃ§Ã£o: DBT

**Por que DBT?**
- âœ… SQL como linguagem de transformaÃ§Ã£o
- âœ… Testes de qualidade built-in
- âœ… DocumentaÃ§Ã£o automÃ¡tica
- âœ… Lineage de dados
- âœ… Versionamento de modelos

**Estrutura de Modelos:**
```
dbt_brt/models/
â”œâ”€â”€ bronze/
â”‚   â””â”€â”€ sources.yml          # DefiniÃ§Ã£o de tabelas externas
â”œâ”€â”€ silver/
â”‚   â”œâ”€â”€ stg_brt_gps_cleaned.sql
â”‚   â””â”€â”€ schema.yml
â””â”€â”€ gold/
    â”œâ”€â”€ fct_brt_line_metrics.sql
    â””â”€â”€ schema.yml
```

### Armazenamento: GCP

**Google Cloud Storage:**
- Camada de staging para CSVs
- Bucket: `gs://brt-data-civitas/brt-data/`
- Formato: CSV com header
- RetenÃ§Ã£o: ConfigurÃ¡vel

**BigQuery:**
- Tabelas externas (Bronze)
- Views materializadas (Silver)
- Tabelas particionadas (Gold)
- Dataset: `brt_dataset`

## DecisÃµes de Design

### 1. Por que Tabela Externa para Bronze?

**Vantagens:**
- âœ… SeparaÃ§Ã£o de armazenamento e computaÃ§Ã£o
- âœ… Custo reduzido (storage em GCS Ã© mais barato)
- âœ… Flexibilidade para processar dados brutos
- âœ… HistÃ³rico completo sem duplicaÃ§Ã£o

**Trade-offs:**
- âš ï¸ Performance de query inferior a tabelas nativas
- âš ï¸ Requer GCS alÃ©m do BigQuery

### 2. Por que View para Silver?

**Vantagens:**
- âœ… Sempre reflete dados mais recentes
- âœ… Sem custo de armazenamento adicional
- âœ… Queries otimizadas pelo BigQuery

**Trade-offs:**
- âš ï¸ RecomputaÃ§Ã£o a cada query

### 3. Por que Tabela Particionada para Gold?

**Vantagens:**
- âœ… Performance otimizada para queries por data
- âœ… Custo reduzido (scan apenas partiÃ§Ãµes necessÃ¡rias)
- âœ… Ideal para dashboards com filtros temporais

**ConfiguraÃ§Ã£o:**
```sql
PARTITION BY date_partition
CLUSTER BY line, period_of_day
```

## Qualidade de Dados

### NÃ­veis de Testes

1. **Testes de Schema (Bronze â†’ Silver)**
   - Campos obrigatÃ³rios nÃ£o nulos
   - Tipos de dados corretos
   - Valores dentro de ranges esperados

2. **Testes de Relacionamento (Silver)**
   - Unicidade de combinaÃ§Ãµes
   - ReferÃªncias vÃ¡lidas

3. **Testes de NegÃ³cio (Gold)**
   - MÃ©tricas dentro de limites esperados
   - ConsistÃªncia de agregaÃ§Ãµes

### Exemplo de Teste DBT

```yaml
# schema.yml
models:
  - name: stg_brt_gps_cleaned
    columns:
      - name: latitude
        tests:
          - not_null
          - dbt_expectations.expect_column_values_to_be_between:
              min_value: -23.0
              max_value: -22.7
```

## Monitoramento e Observabilidade

### MÃ©tricas de Pipeline

1. **Captura:**
   - Taxa de sucesso de requisiÃ§Ãµes API
   - Tempo mÃ©dio de resposta
   - Total de registros capturados

2. **AgregaÃ§Ã£o:**
   - Tamanho dos arquivos CSV
   - Tempo de agregaÃ§Ã£o
   - Registros por arquivo

3. **TransformaÃ§Ã£o:**
   - DuraÃ§Ã£o de cada modelo DBT
   - Linhas processadas
   - Testes falhados

4. **Qualidade:**
   - % de registros vÃ¡lidos
   - Taxa de duplicatas removidas
   - Cobertura de testes

### Alertas Recomendados

- âš ï¸ API indisponÃ­vel por > 5 minutos
- âš ï¸ Buffer nÃ£o completado em 15 minutos
- âš ï¸ Upload GCS falhou
- âš ï¸ Testes DBT falharam
- âš ï¸ LatÃªncia > 2 horas entre captura e disponibilizaÃ§Ã£o Gold

## Escalabilidade

### Capacidade Atual

- **FrequÃªncia:** 1 captura/minuto
- **AgregaÃ§Ã£o:** 10 minutos
- **Volume diÃ¡rio:** ~144 CSVs/dia
- **Registros/dia:** ~200-500 veÃ­culos Ã— 144 capturas = ~28.800-72.000 registros

### Pontos de Escala

1. **Aumentar frequÃªncia:**
   - Modificar `CAPTURE_INTERVAL_SECONDS`
   - Ajustar schedule do Prefect

2. **Processar mÃºltiplas linhas:**
   - Paralelizar capturas por linha
   - Usar Prefect mapping

3. **Otimizar custos BigQuery:**
   - Aumentar granularidade de particionamento
   - Adicionar mais clustering

## Custos Estimados (GCP Free Tier)

- **Cloud Storage:** ~1GB/mÃªs â†’ GrÃ¡tis
- **BigQuery Storage:** ~2GB/mÃªs â†’ GrÃ¡tis
- **BigQuery Queries:** ~10GB processados/mÃªs â†’ GrÃ¡tis
- **Total:** $0/mÃªs dentro do free tier

---

**Desenvolvido seguindo as melhores prÃ¡ticas de Data Engineering** ğŸš€
