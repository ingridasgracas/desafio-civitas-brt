# ğŸ“Š RelatÃ³rio Final - Pipeline BRT CIVITAS

**Candidato:** Ingrid Lima  
**Data:** 24 de Outubro de 2025  
**Projeto:** Pipeline ELT - Dados GPS do BRT Rio de Janeiro

---

## ğŸ¯ Objetivo

Desenvolver um pipeline de dados automatizado que:
1. Capture dados GPS dos Ã´nibus BRT em tempo real
2. Armazene no Google Cloud Storage
3. Crie tabelas no BigQuery
4. Transforme dados seguindo arquitetura Medallion (Bronze â†’ Silver â†’ Gold)

---

## ğŸ—ï¸ Arquitetura Implementada

### **Componentes**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   API BRT RJ    â”‚
â”‚  (Tempo Real)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â†“ HTTP Request (1/min)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Python Script  â”‚
â”‚ (brt_api_capture)â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â†“ AgregaÃ§Ã£o (10 min)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Buffer Local   â”‚
â”‚ (CSV Generator) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â†“ Upload
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Cloud Storage   â”‚
â”‚ (GCS Bucket)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â†“ External Table
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   BigQuery      â”‚
â”‚  ğŸ¥‰ Bronze      â”‚ â† Dados brutos (tabela externa)
â”‚  ğŸ¥ˆ Silver      â”‚ â† Dados limpos (view DBT)
â”‚  ğŸ¥‡ Gold        â”‚ â† MÃ©tricas agregadas (tabela DBT)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### **OrquestraÃ§Ã£o**

- **Prefect 1.4.1**: Agendamento e monitoramento
- **ExecuÃ§Ã£o**: A cada 1 minuto
- **AgregaÃ§Ã£o**: Gera CSV a cada 10 minutos (6 capturas)

---

## ğŸ’» Tecnologias Utilizadas

| Tecnologia | VersÃ£o | Finalidade |
|------------|--------|-----------|
| **Python** | 3.12 | Linguagem principal |
| **Prefect** | 1.4.1 | OrquestraÃ§Ã£o de pipeline |
| **DBT** | 1.5.0 | TransformaÃ§Ã£o de dados (ELT) |
| **Google Cloud Storage** | - | Armazenamento de CSV |
| **BigQuery** | - | Data Warehouse |
| **Pandas** | 2.2.0 | ManipulaÃ§Ã£o de dados |
| **Docker** | 28.4.0 | ContainerizaÃ§Ã£o (opcional) |

---

## ğŸ“ Estrutura do Projeto

```
desafio-civitas-brt/
â”œâ”€â”€ pipeline/
â”‚   â””â”€â”€ brt_flow.py              # Flow principal Prefect
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ brt_api_capture.py       # Captura API
â”‚   â”œâ”€â”€ brt_data_aggregator.py   # AgregaÃ§Ã£o 10min
â”‚   â”œâ”€â”€ gcs_manager.py           # Upload GCS
â”‚   â””â”€â”€ generate_mock_data.py    # Dados de teste
â”œâ”€â”€ dbt_brt/
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ bronze/
â”‚   â”‚   â”‚   â””â”€â”€ sources.yml      # Tabela externa GCS
â”‚   â”‚   â”œâ”€â”€ silver/
â”‚   â”‚   â”‚   â””â”€â”€ stg_brt_gps_cleaned.sql
â”‚   â”‚   â””â”€â”€ gold/
â”‚   â”‚       â””â”€â”€ fct_brt_line_metrics.sql
â”‚   â””â”€â”€ tests/
â”‚       â””â”€â”€ 27 testes de qualidade
â”œâ”€â”€ config/
â”‚   â””â”€â”€ gcp-credentials.json     # Service Account
â”œâ”€â”€ .env                         # VariÃ¡veis de ambiente
â””â”€â”€ docs/                        # DocumentaÃ§Ã£o completa
```

---

## ğŸ¨ Camadas da Arquitetura Medallion

### ğŸ¥‰ **Camada Bronze** (Raw Data)
- **Tabela:** `bronze_brt_gps`
- **Tipo:** External Table (aponta para CSV no GCS)
- **Dados:** Brutos, sem transformaÃ§Ã£o
- **Schema:**
  ```sql
  - dataHora (STRING)
  - ordem (STRING) 
  - linha (STRING)
  - latitude (FLOAT64)
  - longitude (FLOAT64)
  - velocidade (FLOAT64)
  ```

### ğŸ¥ˆ **Camada Silver** (Cleaned Data)
- **View:** `stg_brt_gps_cleaned`
- **TransformaÃ§Ãµes:**
  - âœ… ConversÃ£o de tipos (timestamp, numeric)
  - âœ… ValidaÃ§Ã£o de coordenadas GPS (Rio de Janeiro)
  - âœ… RemoÃ§Ã£o de duplicatas
  - âœ… Campos derivados (data, hora, dia da semana)
  - âœ… CategorizaÃ§Ã£o de velocidade (parado/lento/normal/rÃ¡pido)
  - âœ… IdentificaÃ§Ã£o de perÃ­odo do dia

### ğŸ¥‡ **Camada Gold** (Business Metrics)
- **Tabela:** `fct_brt_line_metrics`
- **Features:**
  - Particionada por data
  - Clusterizada por linha e perÃ­odo
  - AgregaÃ§Ãµes por linha BRT:
    - Velocidade mÃ©dia
    - Total de veÃ­culos
    - DistribuiÃ§Ã£o por categoria de velocidade
    - MÃ©tricas por perÃ­odo do dia

---

## âœ… Testes de Qualidade (27 testes)

### **Testes Bronze:**
- Campos obrigatÃ³rios nÃ£o nulos
- Unicidade de registros
- Valores aceitos para linha BRT

### **Testes Silver:**
- Coordenadas dentro do Rio de Janeiro
- Velocidade em range vÃ¡lido (0-120 km/h)
- Timestamps vÃ¡lidos
- Sem duplicatas

### **Testes Gold:**
- Integridade referencial
- AgregaÃ§Ãµes corretas
- Particionamento funcional

---

## ğŸ“Š Resultados

### **Infraestrutura GCP Criada:**
- âœ… Projeto: `brt-pipeline-civitas`
- âœ… Bucket GCS: `brt-data-civitas`
- âœ… Dataset BigQuery: `brt_dataset`
- âœ… Service Account com permissÃµes

### **Pipeline Funcional:**
- âœ… Captura automÃ¡tica (1 em 1 minuto)
- âœ… AgregaÃ§Ã£o inteligente (10 minutos)
- âœ… Upload automatizado para GCS
- âœ… TransformaÃ§Ãµes DBT executando
- âœ… Testes de qualidade passando

### **Monitoramento:**
- âœ… Prefect Server rodando
- âœ… Interface web em http://localhost:8080
- âœ… Logs detalhados
- âœ… Retry automÃ¡tico em falhas

---

## âš ï¸ Desafios Encontrados

### **1. API BRT InstÃ¡vel**
- **Problema:** API do governo frequentemente indisponÃ­vel
- **SoluÃ§Ã£o:** 
  - Retry automÃ¡tico (3 tentativas)
  - Tratamento de erros com SKIP
  - Gerador de dados mockados para testes

### **2. Compatibilidade de VersÃµes**
- **Problema:** pyarrow incompatÃ­vel com Python 3.12
- **SoluÃ§Ã£o:** Upgrade para pyarrow 14.0.2+

### **3. Prefect 1.x vs 2.x**
- **Problema:** DocumentaÃ§Ã£o misturada entre versÃµes
- **SoluÃ§Ã£o:** Ajustes especÃ­ficos para v1.4.1

---

## ğŸš€ Como Executar

```powershell
# 1. Clonar repositÃ³rio
cd desafio-civitas-brt

# 2. Instalar dependÃªncias
pip install -r requirements.txt

# 3. Configurar credenciais GCP
# Editar .env com PROJECT_ID e credenciais

# 4. Criar recursos GCP
python scripts/create_gcp_resources.py

# 5. Executar pipeline
python pipeline/brt_flow.py

# 6. (Opcional) Iniciar Prefect UI
prefect server start
# Acessar: http://localhost:8080
```

---

## ğŸ“ˆ PrÃ³ximos Passos (Melhorias Futuras)

1. **VisualizaÃ§Ã£o:**
   - Dashboard no Looker Studio
   - Mapa de calor com posiÃ§Ãµes dos Ã´nibus
   - GrÃ¡ficos de velocidade mÃ©dia por linha

2. **Alertas:**
   - NotificaÃ§Ã£o de Ã´nibus parados por muito tempo
   - Alerta de atrasos por linha
   - Monitoramento de falhas da API

3. **OtimizaÃ§Ãµes:**
   - Streaming com Pub/Sub
   - Processamento em tempo real com Dataflow
   - Cache de dados para reduzir chamadas Ã  API

4. **Deploy ProduÃ§Ã£o:**
   - Cloud Run para executar pipeline
   - Cloud Scheduler para agendamento
   - Cloud Monitoring para observabilidade

---

## ğŸ“š DocumentaÃ§Ã£o

- `README.md` - VisÃ£o geral do projeto
- `ARCHITECTURE.md` - Arquitetura detalhada
- `GUIA_EXECUCAO.md` - InstruÃ§Ãµes de execuÃ§Ã£o
- `docs/GCP_SETUP.md` - ConfiguraÃ§Ã£o GCP
- `CHANGELOG.md` - HistÃ³rico de mudanÃ§as

---

## ğŸ“ Aprendizados

1. **OrquestraÃ§Ã£o:** Prefect oferece Ã³tima visibilidade do pipeline
2. **DBT:** Excelente para transformaÃ§Ãµes SQL versionadas
3. **GCP:** IntegraÃ§Ã£o nativa com BigQuery facilita muito
4. **ResiliÃªncia:** Retry automÃ¡tico Ã© essencial para APIs instÃ¡veis
5. **Testes:** DBT tests garantem qualidade desde o inÃ­cio

---

## âœ¨ ConclusÃ£o

Pipeline completo implementado com sucesso, seguindo todas as especificaÃ§Ãµes:
- âœ… Captura automatizada de dados
- âœ… Armazenamento em Cloud Storage
- âœ… TransformaÃ§Ã£o em camadas (Medallion)
- âœ… Testes de qualidade
- âœ… OrquestraÃ§Ã£o com Prefect
- âœ… DocumentaÃ§Ã£o completa

O pipeline estÃ¡ pronto para produÃ§Ã£o, aguardando apenas a estabilizaÃ§Ã£o da API BRT para captura de dados reais.

---

**Desenvolvido com â¤ï¸ para o Desafio CIVITAS**
